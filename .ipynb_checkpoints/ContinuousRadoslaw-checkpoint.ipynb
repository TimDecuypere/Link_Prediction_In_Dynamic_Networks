{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# node2vec\n",
    "---\n",
    "[node2vec](http://snap.stanford.edu/node2vec/) for link prediction:\n",
    "1. Perform train-test split\n",
    "1. Train skip-gram model on random walks within training graph\n",
    "2. Get node embeddings from skip-gram model\n",
    "3. Create bootstrapped edge embeddings by taking the Hadamard product of node embeddings\n",
    "4. Train a logistic regression classifier on these edge embeddings (possible edge --> edge score between 0-1)\n",
    "5. Evaluate these edge embeddings on the validation and test edge sets\n",
    "\n",
    "node2vec source code: https://github.com/aditya-grover/node2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: Dynamic Enron employees\n",
    "Number of nodes: 151\n",
    "Number of edges: 1612\n",
    "Number of time frames: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in Graph Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as scp\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import pickle\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load in the networks, make the training and test edge lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899\n",
      "7046\n"
     ]
    }
   ],
   "source": [
    "MasterGraph = nx.read_edgelist(\"fb-forum/fb-forum-m.csv\", nodetype=int, delimiter=\",\")\n",
    "for edge in MasterGraph.edges():\n",
    "    MasterGraph[edge[0]][edge[1]]['weight'] = 1\n",
    "\n",
    "print MasterGraph.number_of_nodes()\n",
    "print MasterGraph.number_of_edges()\n",
    "\n",
    "with open('fb-forum/fb-forum-m15-weighted.csv', 'rb') as f:\n",
    "    weighted_edges_15 = [[int(x) for x in rec] for rec in csv.reader(f, delimiter=',')]\n",
    "    weighted_edges_15 = map(tuple, weighted_edges_15)\n",
    "\n",
    "G15 = nx.MultiGraph()\n",
    "G15.add_weighted_edges_from(weighted_edges_15)\n",
    "\n",
    "\n",
    "G6 = nx.read_edgelist(\"fb-forum/fb-forum-m6.csv\", nodetype = int, delimiter = \",\")\n",
    "for edge in G6.edges():\n",
    "    G6[edge[0]][edge[1]]['weight'] = 1\n",
    "#G8 = nx.MultiGraph(G8)\n",
    "#G17 = nx.read_edgelist(\"Enron-employees/m_enron_employees_17.csv\", nodetype = int, delimiter = \",\")\n",
    "#for edge in G17.edges():\n",
    "#    G17[edge[0]][edge[1]]['weight'] = 1\n",
    "#\n",
    "    \n",
    "    \n",
    "## All the nodes are in MasterNodes    \n",
    "MasterNodes = MasterGraph.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##for edge in G17.edges():\n",
    "#    #print edge\n",
    "#    \n",
    "#for j in range(0,len(G17[1][2])):\n",
    "#    print 'j', j\n",
    "#    print len(G17[1][2])\n",
    "#    print G17[1][2]\n",
    "#    print G17[1][2][j]\n",
    "#    print ' '\n",
    "#    \n",
    "#    \n",
    "##\n",
    "##print G17[2][1]\n",
    "##\n",
    "##if G17[4][2][0]['weight'] > G17[1][2][1]['weight']:\n",
    "##    print 'yep'\n",
    "#\n",
    "#print G17[3][2]\n",
    "#print G17[2][3]\n",
    "#print len(G17[2][3])\n",
    "#G17.remove_edges_from([(3,2)]*len(G17[2][3]))\n",
    "#print G17.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training - Test split  \n",
    "'''''\n",
    "first add all the nodes that are in MasterGraph but not in \n",
    "G8\n",
    "'''''\n",
    "for i in MasterNodes:\n",
    "    if i not in G6.nodes():\n",
    "        G6.add_node(i)\n",
    "        \n",
    "adj_sparse = nx.to_scipy_sparse_matrix(G6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gae.preprocessing import mask_test_edges\n",
    "np.random.seed(0) # make sure train-test split is consistent between notebooks\n",
    "\n",
    "adj_sparse = nx.to_scipy_sparse_matrix(G6)\n",
    "\n",
    "adj_train_del_del, train_edges, train_edges_false, val_edges, val_edges_false, \\\n",
    "    test_edges, test_edges_false = mask_test_edges(adj_sparse, test_frac=.3, val_frac=.0, prevent_disconnect = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes: 899\n",
      "Total edges: 505\n",
      "Training edges (positive): 354\n",
      "Training edges (negative): 354\n",
      "Validation edges (positive): 0\n",
      "Validation edges (negative): 0\n",
      "Test edges (positive): 151\n",
      "Test edges (negative): 151\n"
     ]
    }
   ],
   "source": [
    "# Inspect train/test split\n",
    "print \"Total nodes:\", adj_sparse.shape[0]\n",
    "print \"Total edges:\", int(adj_sparse.nnz/2) # adj is symmetric, so nnz (num non-zero) = 2*num_edges\n",
    "print \"Training edges (positive):\", len(train_edges)\n",
    "print \"Training edges (negative):\", len(train_edges_false)\n",
    "print \"Validation edges (positive):\", len(val_edges)\n",
    "print \"Validation edges (negative):\", len(val_edges_false)\n",
    "print \"Test edges (positive):\", len(test_edges)\n",
    "print \"Test edges (negative):\", len(test_edges_false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The positive training edges are in the edgelist \"train_edges\".\n",
    "\n",
    "The negative training edges are in the edgelist \"train_edges_false\".\n",
    "\n",
    "The positive test edges are in the edgelist \"test_edges\".\n",
    "\n",
    "The negative test edges are in the edgelist \"test_edges_false\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: add all the nodes in G1, G2, G3 that are not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "add all the nodes that are in the MasterGraph but not in \n",
    "G1, G2 and G3\n",
    "'''\n",
    "for i in MasterNodes:\n",
    "    if i not in G15.nodes():\n",
    "        G15.add_node(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges before removal: \n",
      "G15:   32817\n",
      "Edges after removal: \n",
      "G17:   32729\n"
     ]
    }
   ],
   "source": [
    "print \"Edges before removal: \"\n",
    "print \"G15:  \", G15.number_of_edges()\n",
    "\n",
    "\n",
    "'''\n",
    "for every snapshot, delete all the edges that occur in the \n",
    "test set, this is important because the training of node2vec\n",
    "can only be done on the training network and not on edges that\n",
    "are used for testing\n",
    "'''\n",
    "for i in range(0,len(test_edges)):\n",
    "        if G15.has_edge(test_edges[i, 0], test_edges[i, 1]):\n",
    "            G15.remove_edges_from([(test_edges[i, 0], test_edges[i, 1])]*len(G15[test_edges[i, 0]][test_edges[i, 1]]))\n",
    "            \n",
    "print \"Edges after removal: \"\n",
    "print \"G17:  \", G15.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train node2vec (Learn Node Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim_Dell_XPS\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import node2vecWeight_bidirectional as node2vec\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node2vec settings\n",
    "# NOTE: When p = q = 1, this is equivalent to DeepWalk\n",
    "\n",
    "P = 1 # Return hyperparameter\n",
    "Q = 1 # In-out hyperparameter\n",
    "WINDOW_SIZE = 10 # Context size for optimization\n",
    "NUM_WALKS = 10 # Number of walks per source\n",
    "WALK_LENGTH = 80 # Length of walk per source\n",
    "DIMENSIONS = 128 # Embedding dimension\n",
    "DIRECTED = False # Graph directed/undirected\n",
    "WORKERS = 8 # Num. parallel workers\n",
    "ITER = 1 # SGD epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk iteration:\n",
      "1 / 10\n",
      "2 / 10\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing, generate walks\n",
    "G15_n2v = node2vec.Graph(G15, DIRECTED, P, Q)\n",
    "G15_n2v.preprocess_transition_probs()\n",
    "\n",
    "walksG15 = G15_n2v.simulate_walks(NUM_WALKS, WALK_LENGTH)\n",
    "\n",
    "walksG15 = [map(str, walk) for walk in walksG15]\n",
    "\n",
    "# Train skip-gram model\n",
    "modelG15 = Word2Vec(walksG15, size=DIMENSIONS, window=WINDOW_SIZE, min_count=0, sg=1, workers=WORKERS, iter=ITER)\n",
    "\n",
    "\n",
    "# Store embeddings mapping\n",
    "emb_mappingsG15 = modelG15.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Edge Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G17 = nx.Graph(G17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create node embeddings matrix (rows = nodes, columns = embedding features)\n",
    "emb_listG15 = []\n",
    "\n",
    "for node_index in range(1, adj_sparse.shape[0]+1):\n",
    "    node_str = str(node_index)\n",
    "    \n",
    "    node_embG15 = emb_mappingsG15[node_str]\n",
    "    emb_listG15.append(node_embG15)\n",
    "    \n",
    "emb_matrixG15 = np.vstack(emb_listG15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_embeddings_static(edge_list):\n",
    "    embs_s = []\n",
    "    for edge in edge_list:\n",
    "        \n",
    "        node1 = edge[0]\n",
    "        node2 = edge[1]\n",
    "        \n",
    "        embG15_1 = emb_matrixG15[node1]\n",
    "        embG15_2 = emb_matrixG15[node2]\n",
    "        \n",
    "        edge_embG15 = np.multiply(embG15_1, embG15_2)\n",
    "        embs_s.append(edge_embG15)\n",
    "        \n",
    "    embs_s = np.array(embs_s)\n",
    "    \n",
    "    return embs_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STATIC\n",
    "# Train-set edge embeddings\n",
    "pos_train_edge_embs_s = get_edge_embeddings_static(train_edges)\n",
    "neg_train_edge_embs_s = get_edge_embeddings_static(train_edges_false)\n",
    "train_edge_embs_s = np.concatenate([pos_train_edge_embs_s, neg_train_edge_embs_s])\n",
    "\n",
    "# Create train-set edge labels: 1 = real edge, 0 = false edge\n",
    "train_edge_labels = np.concatenate([np.ones(len(train_edges)), np.zeros(len(train_edges_false))])\n",
    "\n",
    "# Val-set edge embeddings, labels\n",
    "pos_val_edge_embs_s = get_edge_embeddings_static(val_edges)\n",
    "neg_val_edge_embs_s = get_edge_embeddings_static(val_edges_false)\n",
    "val_edge_embs_s = np.concatenate([pos_val_edge_embs_s, neg_val_edge_embs_s])\n",
    "val_edge_labels = np.concatenate([np.ones(len(val_edges)), np.zeros(len(val_edges_false))])\n",
    "\n",
    "# Test-set edge embeddings, labels\n",
    "pos_test_edge_embs_s = get_edge_embeddings_static(test_edges)\n",
    "neg_test_edge_embs_s = get_edge_embeddings_static(test_edges_false)\n",
    "test_edge_embs_s = np.concatenate([pos_test_edge_embs_s, neg_test_edge_embs_s])\n",
    "\n",
    "# Create val-set edge labels: 1 = real edge, 0 = false edge\n",
    "test_edge_labels = np.concatenate([np.ones(len(test_edges)), np.zeros(len(test_edges_false))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Edge Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the basic topological classifiers are calculated for the test and training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression classifier on train-set edge embeddings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "edge_classifier_lr_stat = LogisticRegression(random_state=0)\n",
    "edge_classifier_lr_stat.fit(train_edge_embs_s, train_edge_labels)\n",
    "\n",
    "\n",
    "edge_classifier_RF_stat = RandomForestClassifier(n_estimators = 50)\n",
    "edge_classifier_RF_stat.fit(train_edge_embs_s, train_edge_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Gradient Boosted Regression Trees\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "edge_classifier_gb_stat = GradientBoostingClassifier(n_estimators=50, learning_rate=0.5, max_depth=8, random_state=0).fit(train_edge_embs_s, train_edge_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted edge scores: probability of being of class \"1\" (real edge)\n",
    "# val_preds = edge_classifier.predict_proba(val_edge_embs)[:, 1]\n",
    "# val_roc = roc_auc_score(val_edge_labels, val_preds)\n",
    "# val_ap = average_precision_score(val_edge_labels, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted edge scores: probability of being of class \"1\" (real edge)\n",
    "test_preds_lr_s = edge_classifier_lr_stat.predict_proba(test_edge_embs_s)[:, 1]\n",
    "test_roc_lr_s = roc_auc_score(test_edge_labels, test_preds_lr_s)\n",
    "test_ap_lr_s = average_precision_score(test_edge_labels, test_preds_lr_s)\n",
    "\n",
    "\n",
    "test_preds_rf_s = edge_classifier_RF_stat.predict_proba(test_edge_embs_s)[:, 1]\n",
    "test_roc_rf_s = roc_auc_score(test_edge_labels, test_preds_rf_s)\n",
    "test_ap_rf_s = average_precision_score(test_edge_labels, test_preds_rf_s)\n",
    "\n",
    "\n",
    "test_preds_gb_s = edge_classifier_gb_stat.predict_proba(test_edge_embs_s)[:, 1]\n",
    "test_roc_gb_s = roc_auc_score(test_edge_labels, test_preds_gb_s)\n",
    "test_ap_gb_s = average_precision_score(test_edge_labels, test_preds_gb_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print 'node2vec Validation ROC score: ', str(val_roc)\n",
    "# print 'node2vec Validation AP score: ', str(val_ap)\n",
    "print 'node2vec Test ROC score logistic regression static: ', str(test_roc_lr_s)\n",
    "print 'node2vec Test ROC score random forest static: ', str(test_roc_rf_s)\n",
    "print 'node2vec Test ROC score gradient boosting static: ', str(test_roc_gb_s)\n",
    "print 'node2vec Test AP score logistic regression static: ', str(test_ap_lr_s)\n",
    "print 'node2vec Test AP score random forest static: ', str(test_ap_rf_s)\n",
    "print 'node2vec Test AP score gradient boosting static: ', str(test_ap_gb_s)\n",
    "\n",
    "print str(test_roc_lr_s)\n",
    "print str(test_roc_rf_s)\n",
    "print str(test_roc_gb_s)\n",
    "print str(test_ap_lr_s)\n",
    "print str(test_ap_rf_s)\n",
    "print str(test_ap_gb_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ROC curve\n",
    "fpr_lr_s, tpr_lr_s, _ = roc_curve(test_edge_labels, test_preds_lr_s)\n",
    "fpr_rf_s, tpr_rf_s, _ = roc_curve(test_edge_labels, test_preds_rf_s)\n",
    "fpr_gb_s, tpr_gb_s, _ = roc_curve(test_edge_labels, test_preds_gb_s)\n",
    "\n",
    "\n",
    "fig_roc = plt.figure()\n",
    "\n",
    "plt.plot([0,1], [0, 1], 'k--')\n",
    "plt.step(fpr_lr_s, tpr_lr_s, color = \"b\", alpha = 1, where = 'post', label = \"Logistic Regression/Static\")\n",
    "plt.step(fpr_rf_s, tpr_rf_s, color = \"salmon\", alpha = 1, where = 'post', label = \"Random Forest/Static\")\n",
    "plt.step(fpr_gb_s, tpr_gb_s, color = \"red\", alpha = 1, where = 'post', label = \"Gradient Boosting/Static\")\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('ROC curve Enron employees')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "#fig_roc.savefig(\"ROC_Enron.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
